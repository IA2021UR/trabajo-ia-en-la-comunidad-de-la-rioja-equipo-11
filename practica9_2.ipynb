{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "practica9_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IA2021UR/trabajo-ia-en-la-comunidad-de-la-rioja-equipo-11/blob/main/practica9_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6phqqXPIv6hp"
      },
      "source": [
        "# Práctica 9 Parte 2: Análisis de sentimientos\n",
        "\n",
        "El análisis de sentimientos es un problema de procesado de lenguaje natural donde se pretende conocer la intención de un texto. En esta práctica vamos a ver cómo predecir el sentimiento, positivo o negativo, de una valoracion de una película.\n",
        "\n",
        "En esta ocasión vamos a utilizar la librería de deep learning [Keras](https://keras.io/).\n",
        "\n",
        "\n",
        "En esta práctica es importante que actives el uso de GPU. Para ello ve al menú Edit -> Notebook settings y en la opción Hardware accelerator selecciona la opción de GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuxiF_2TwdXJ"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "El dataset usado en esta sesión es el dataset [IMDB](http://ai.stanford.edu/~amaas/data/sentiment/). Dicho dataset contiene 25000 valoraciones (positivas y negativas) para entrenar, y 25000 valoraciones  para testear. El objetivo es ser capaz de determinar si una valoración de una película es positiva o negativa. \n",
        "\n",
        "Keras proporciona acceso directo al dataset IMDB en un formato listo para ser usado por las redes neuronales, lo que evita tener que descargarlo y procesarlo. La función ``imdb.load_data()`` permite cargar el dataset donde las palabras han sido reemplazadas por enteros que indican la popularidad (número de apariciones)  de una palabra en el dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKUmkF-Kv5nK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e42888c-2c1d-424f-a9a7-ddfd9b01b9f6"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.datasets import imdb\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "(X_train,y_train), (X_test,y_test) = imdb.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUgMh_RNxqxN"
      },
      "source": [
        "A continuación mostramos la forma del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-6xEME5xhSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089cc546-b632-4d97-d33c-852981f014d2"
      },
      "source": [
        "print(\"Datos entrenamiento: \")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(\"Datos test: \")\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datos entrenamiento: \n",
            "(25000,)\n",
            "(25000,)\n",
            "Datos test: \n",
            "(25000,)\n",
            "(25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3tU1rzR02ml"
      },
      "source": [
        "Podemos también mostrar que aspecto tienen los elementos de nuestro dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp1zZjX30XvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7615e498-cc45-4971-b126-1f44889ab65b"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 22665,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 21631,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 31050,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vny1jGOW07rt"
      },
      "source": [
        "A partir de la instrucción anterior podemos ver que los elementos de nuestro dataset se representan mediante una lista de enteros, donde cada entero está asociado a una palabra. Para restaurar el mensaje original podemos ejecutar el siguiente comando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U-wuB5V1HlN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "ba60a1d2-2deb-4a68-c4c5-32e203dc9328"
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "' '.join([reverse_word_index.get(i - 3, '?') for i in X_train[0]])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2xguDlUx4HE"
      },
      "source": [
        "Podemos también mostrar el número de clases (veremos que nos devuelve dos clases, el 0 representa una valoración negativa y el 1 una valoración positiva)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2Is1hLMx3lH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5874ef8d-5518-43e3-ef97-bebc7eb8853c"
      },
      "source": [
        "print(\"Clases: \")\n",
        "print(np.unique(y_train))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clases: \n",
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXAyv1tRyA0p"
      },
      "source": [
        "También podemos ver el número total de palabras del dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-wdh746x0ys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82e7097a-1b4f-4d89-d2fb-3a967c7d8bf3"
      },
      "source": [
        "print(\"Número de palabras: \")\n",
        "print(len(np.unique(np.hstack(X_train))))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número de palabras: \n",
            "88585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI_wbtThyLeE"
      },
      "source": [
        "Finalmente, podemos ver la longitud media de las valoraciones. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDpgxcCKyHZy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "3002103d-cb93-40d8-8ee8-4a7ba7177fee"
      },
      "source": [
        "print(\"Longitud media: \")\n",
        "result = [len(x) for x in X_train]\n",
        "print(\"Media %.2f palabras (%f)\" % (np.mean(result),np.std(result)))\n",
        "plt.subplot(121)\n",
        "plt.boxplot(result)\n",
        "plt.subplot(122)\n",
        "plt.hist(result)\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longitud media: \n",
            "Media 238.71 palabras (176.493674)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sporAx6Fy8U2"
      },
      "source": [
        "##### Ejercicio\n",
        "A partir de los diagramas anteriores, ¿qué puedes decir del tamaño de las valoraciones? ¿Cuál sería el tamaño de la valoración más larga (para esta pregunta puedes ejecutar alguna instrucción adicional)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nugLHcBmyVpl"
      },
      "source": [
        "El tamaño de las valoraciones tiene una media de 238 palabras aproximadamente. Además, se observan una gran cantidad de valores atípicos en el bigote superior. En cambio, apenas existen en el inferior. Respecto a la valoración más larga, corresponde al valor más alejado, alrededorde las 2500 palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK8fKDD8zU1N"
      },
      "source": [
        "## Word embeddings\n",
        "\n",
        "Como ya hemos visto, uno de los grandes avances más recientes en el área del procesamiento de lenguaje natural son los *word embeddings*. Los *word embeddings* son una técnica donde las palabras se codifican como vectores de reales en un espacio de dimensión alta, donde las similaridad entre palabras se traduce en cercanía de los vectores. Esto s muy útil ya que al trabajar con redes neuronales se requiere una conversión de las palabras a números. \n",
        "\n",
        "Por el momento no vamos a usar ningún word embedding de los vistos con anterioridad, sino que vamos aprenderlos directamente a partir de nuestros datos. Keras proporciona una manera sencilla de convertir representaciones de palabras mediante enteros positios a un word embedding mediante una capa de ``Embedding``. Esta capa toma argumentos que definen la asociación de palabras a vectores. Estos argumentos incluyen el número máximo de palabras esperadas, también conocido como el tamaño del vocabulario. Esta capa también permite especificar la dimensionalidad de la representación.\n",
        "\n",
        "Queremos usar una representación para nuestro dataset. Digamos que estamos interesados en las 5000 palabras más usadas del dataset. Por lo tanto, nuestro vocabulario tendrá 5000 elementos. También podemos elegir usar un vector de dimensión 32 para representar cada una de las palabras. Finalmente, podemos fijar que la longitud máxima de las valoraciones sea de 500 palabras, truncando aquellas que son más largas y añadiendo ceros a las que son más cortas. Vamos a obtener de nuevo nuestro dataset teniendo esto en cuenta. También vamos a definir un conjunto de validación usando el 20% del conjunto de entrenamiento. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_NDC7Nb18NR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a7ece5-1ec3-4fa6-ddc0-665e3087e2f5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "(X_train,y_train), (X_test,y_test) = imdb.load_data(num_words=5000)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=15)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SK9-Tl_hb_8"
      },
      "source": [
        "Podemos ahora truncar o completar cada una de las valoraciones para que contenga 500 palabras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSzzZrpMhbvc"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnzqo7W1hsjS"
      },
      "source": [
        "## Modelo Red Neuronal Simple\n",
        "\n",
        "Vamos a construir varios modelos para nuestro dataset. Comenzaremos con una red neuronal multicapa con una única capa oculta. La innovación será la capa de word embedding que muestra cómo se pueden conseguir buenos resultados con un modelo tan simple. \n",
        "\n",
        "Comenzamos importando las funciones necesarias e inicializando una semilla para obtener resultados consistentes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRgSo0KxhVpk"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "seed = 15\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4WK-RLKiOc1"
      },
      "source": [
        "A continuación creamos nuestro modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWSEjE-FiMIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f49679-34c1-450b-cee2-d37e9b5efab7"
      },
      "source": [
        "top_words = 5000\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(top_words,32,input_length=max_words))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(250,activation='relu'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "model1 = create_model()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 250)               4000250   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 4,160,501\n",
            "Trainable params: 4,160,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3lFAC4Qim6l"
      },
      "source": [
        "Vamos ahora a entrenar el modelo y a mostrar su curva de entrenamiento y validación. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka-LkfnTikox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65d50583-c246-4ef6-8d13-f49e4b4e38f8"
      },
      "source": [
        "history = model1.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=10,batch_size=128,verbose=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 16s 14ms/step - loss: 0.6471 - accuracy: 0.5805 - val_loss: 0.3260 - val_accuracy: 0.8580\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.1921 - accuracy: 0.9263 - val_loss: 0.3048 - val_accuracy: 0.8778\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.0643 - accuracy: 0.9846 - val_loss: 0.3996 - val_accuracy: 0.8668\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.0129 - accuracy: 0.9985 - val_loss: 0.5095 - val_accuracy: 0.8584\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.5459 - val_accuracy: 0.8676\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 8.7956e-04 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.8666\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 4.6928e-04 - accuracy: 1.0000 - val_loss: 0.6038 - val_accuracy: 0.8672\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 2.9681e-04 - accuracy: 1.0000 - val_loss: 0.6245 - val_accuracy: 0.8662\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 2.2776e-04 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.8676\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 1.7311e-04 - accuracy: 1.0000 - val_loss: 0.6551 - val_accuracy: 0.8672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oai2aUhzj1ru",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "19999568-a92b-4dcc-be3f-ad5b15215de4"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'bo')\n",
        "plt.plot(epochs, val_acc, 'b')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze17EMFCkr8J"
      },
      "source": [
        "##### Ejercicio\n",
        "A partir de las gráficas anteriores ¿qué problema tiene nuestro modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWpWs2Nckwzl"
      },
      "source": [
        "Respuesta: para tantas épocas, disponemos de un vocabulario demasiado pequeño y el modelo de sobreajusta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIZkZl59k47Z"
      },
      "source": [
        "Para evitar el problema anterior, vamos a entrenar de nuevo nuestra red, pero sólo 2 épocas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6FNEw_nkwRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f69aa97-a14b-4275-c350-ab1ed88f27a3"
      },
      "source": [
        "model2 = create_model()\n",
        "model2.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=2,batch_size=128,verbose=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 16000)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 250)               4000250   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 4,160,501\n",
            "Trainable params: 4,160,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/2\n",
            "157/157 [==============================] - 3s 13ms/step - loss: 0.6611 - accuracy: 0.5774 - val_loss: 0.3250 - val_accuracy: 0.8594\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.2162 - accuracy: 0.9155 - val_loss: 0.2931 - val_accuracy: 0.8804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f17961338d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6GSdAl0lR3d"
      },
      "source": [
        "Por último, evaluamos nuestro modelo en el conjunto de test. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK6mqa7ilC-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3897a639-4275-48ed-892c-c55513761fb8"
      },
      "source": [
        "scores = model2.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 87.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC52vpEllnzr"
      },
      "source": [
        "Podemos también evaluar el modelo que tenía el problema y podemos ver que la accuracy es peor que la que hemos obtenido con el otro modelo, a pesar de haberlo entrenado por menos tiempo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq1mZ62ilcyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af75e27-c4f5-419a-f477-5f8bfa3d3a46"
      },
      "source": [
        "scores = model1.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 86.46%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjnMFte6l3KI"
      },
      "source": [
        "## Red neuronal convolucional de una dimensión\n",
        "\n",
        "Las redes neuronales convolucionales fueron creadas para tener en cuenta la estructura espacial de los datos en imágenes siendo robustas a cambios en la posición y orientación de los objetos. Este mismo principio se puede aplicar a secuencias como son las secuencias 1-dimensionales de palabras de una valoración de película.  Vamos a utilizar dicha propiedad en nuestro problema. \n",
        "\n",
        "Comenzamos cargando las librerías necesarias para trabajar con redes convolucionales 1-dimensionales. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZOstGNRl0tt"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Convolution1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlWLECjrmu7T"
      },
      "source": [
        "Definimos el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQrHI4dBmswa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e167ee38-16a8-4f9e-80f7-12cdd83aa908"
      },
      "source": [
        "def create_cnn_model():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(top_words,32,input_length=max_words))\n",
        "  model.add(Convolution1D(filters=32,kernel_size=3,padding='same',activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(250,activation='relu'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "model3 = create_cnn_model()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 500, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 250, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 8000)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 250)               2000250   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 2,163,605\n",
            "Trainable params: 2,163,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6afTi6sNnPNy"
      },
      "source": [
        "Entrenamos este nuevo modelo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRzY8kF4nLym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db1c4c8-16a9-49b2-bc72-883b2012f4e8"
      },
      "source": [
        "model3.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=2,batch_size=128,verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "157/157 [==============================] - 32s 14ms/step - loss: 0.6695 - accuracy: 0.5558 - val_loss: 0.3537 - val_accuracy: 0.8510\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.2468 - accuracy: 0.9050 - val_loss: 0.2830 - val_accuracy: 0.8818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f17951e76d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHSZVP6_nWYF"
      },
      "source": [
        "Y evaluamos su precisión. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwzB0dVqnUXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9af1a17-4c5c-4650-9071-1a659c7dcf3a"
      },
      "source": [
        "scores = model3.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 87.26%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsbGqqqyndQ2"
      },
      "source": [
        "Como podemos ver, este modelo mejora los resultados obtenidos con el modelo anterior. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mDQSJRQnrQs"
      },
      "source": [
        "## LSTM\n",
        "\n",
        "Vamos a crear ahora una pequeña red LSTM. Como en casos anteriores comenzamos cargando las librerías necesarias. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aWkJRNRnbCu"
      },
      "source": [
        "from keras.layers import LSTM"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR1BM2Z2n2vx"
      },
      "source": [
        "Definimos el modelo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrX9oAPKn1XD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9db3a4d-4824-4b61-91e9-5c4d67dc9813"
      },
      "source": [
        "def create_lstm_model():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(top_words,32,input_length=max_words))\n",
        "  model.add(LSTM(100))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "model4 = create_lstm_model()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rSULKl_oOQG"
      },
      "source": [
        "Entrenamos el modelo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfXNhtt7oIAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e30a576-597d-4796-ebd9-a640ec9c57cf"
      },
      "source": [
        "model4.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=2,batch_size=128,verbose=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "157/157 [==============================] - 12s 41ms/step - loss: 0.6320 - accuracy: 0.6223 - val_loss: 0.3343 - val_accuracy: 0.8576\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 0.3016 - accuracy: 0.8765 - val_loss: 0.3161 - val_accuracy: 0.8614\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f17970e5890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ5frttYobKh"
      },
      "source": [
        "Y por último lo evaluamos contra el conjunto de test. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTLDWgMgoac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca63cc8-b429-4859-c35f-11bf9d272b93"
      },
      "source": [
        "scores = model4.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 86.35%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8bqux5Xppmv"
      },
      "source": [
        "## LSTM con Dropout\n",
        "\n",
        "Uno de los problemas que tienen todas las redes que hemos definido hasta ahora es que tienden a sobreajustarse muy rápido. Para evitar dicho problema se puede utilizar la técnica de Dropout. \n",
        "\n",
        "Para ello definimos el siguiente modelo. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTen2yrTH2-7"
      },
      "source": [
        "from keras.layers import Dropout"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGsBXaOqohAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a2c02a-567a-4094-a68e-3a1f3aeebe12"
      },
      "source": [
        "def create_lstm_dropout_model():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(top_words,32,input_length=max_words))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(LSTM(100,dropout=0.2,recurrent_dropout=0.2))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "model5 = create_lstm_dropout_model()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 500, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUkSHypcqWSA"
      },
      "source": [
        "##### Ejercicio\n",
        "\n",
        "¿Por cuántas épocas puedes entrenar el nuevo modelo hasta que aparece el sobreajuste?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5A8Z6yKqNgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4809a39-4fc6-4998-9c2f-448dcf1deb6d"
      },
      "source": [
        "model5.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=10,batch_size=128,verbose=1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 272s 2s/step - loss: 0.2977 - accuracy: 0.8805 - val_loss: 0.3039 - val_accuracy: 0.8752\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 270s 2s/step - loss: 0.2527 - accuracy: 0.9031 - val_loss: 0.3042 - val_accuracy: 0.8768\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 269s 2s/step - loss: 0.2243 - accuracy: 0.9139 - val_loss: 0.2976 - val_accuracy: 0.8768\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 270s 2s/step - loss: 0.2152 - accuracy: 0.9172 - val_loss: 0.3425 - val_accuracy: 0.8774\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 270s 2s/step - loss: 0.1951 - accuracy: 0.9264 - val_loss: 0.3353 - val_accuracy: 0.8818\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 272s 2s/step - loss: 0.1834 - accuracy: 0.9312 - val_loss: 0.3278 - val_accuracy: 0.8642\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 271s 2s/step - loss: 0.1730 - accuracy: 0.9360 - val_loss: 0.3295 - val_accuracy: 0.8744\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 272s 2s/step - loss: 0.1608 - accuracy: 0.9402 - val_loss: 0.3514 - val_accuracy: 0.8704\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 269s 2s/step - loss: 0.1419 - accuracy: 0.9484 - val_loss: 0.3992 - val_accuracy: 0.8494\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 269s 2s/step - loss: 0.1417 - accuracy: 0.9472 - val_loss: 0.3955 - val_accuracy: 0.8706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f178c668fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJBo7mjwFJB_"
      },
      "source": [
        "El entrenamiento de este modelo es bastante largo, por lo que no he considerado conveniente poner más de 10 épocas. No muestra sobreajuste con este número."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me8f6oPeq19p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "f9e6d09a-493f-493e-8ef8-688b698b646e"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'bo')\n",
        "plt.plot(epochs, val_acc, 'b')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQIuOOWXqxby"
      },
      "source": [
        "##### Ejercicio\n",
        "¿Qué accuracy consigues obtener con este nuevo modelo?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG5-xqfGqgPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9545dc80-c327-4a97-959e-90f25ab06fd0"
      },
      "source": [
        "scores = model5.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 86.64%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtNaqjrGq99k"
      },
      "source": [
        "## Predicciones propias\n",
        "\n",
        "Una vez construido nuestro modelo nos interesa probarlo con nuestras propias valoraciones. Para ello debemos convertir la frase a un formato que pueda alimentar a la red como se muestra a continuación. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDDVBruxrNa9"
      },
      "source": [
        "review = \"i generally love this type of movie however this time i found myself wanting to kick the screen since i can't do that i will just complain about it this was absolutely awful\"\n",
        "review = review.split(\" \")\n",
        "review = [word_index[w] for w in review]\n",
        "review = sequence.pad_sequences([review], maxlen=max_words)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhooNGoUsHvN"
      },
      "source": [
        "Y hacer la predicción con uno de nuestros modelos. Utilizaremos el de mayor precisión:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E2_-XncrVHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fa12d8d-33ac-47e6-8f28-cd54699f0bcc"
      },
      "source": [
        "model3.predict(review)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16633181]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzXx3K-_tJcM"
      },
      "source": [
        "## Ejercicio obligatorio\n",
        "\n",
        "El problema que hemos visto es un problema de clasificación binaria, existe otro dataset, [Reuters](https://keras.io/api/datasets/reuters/), para la clasificación multiclase (dicho dataset está disponible en [Keras](https://keras.io/datasets/#reuters-newswire-topics-classification)). El ejercicio consite en entrenar un modelo (utilizando las mismas ideas presentadas en este notebook) para dicho problema. Ten en cuenta que con dicho dataset no podrás utilizar como función de pérdida ``binary_crossentropy`` (preparada para problemas binarios) sino que deberás usar la función de pérdida ``categorical_crossentropy``. Añade a continuación todas las celdas que necesites. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqlF8r5GODAF"
      },
      "source": [
        "En primerlugar, descargamos el dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7SJBHgytI0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7855ed1-5a87-4598-d6f2-a1429dfb8785"
      },
      "source": [
        "from keras.datasets import reuters\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(X_train,y_train), (X_test,y_test) = reuters.load_data(num_words=5000)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=15)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/reuters.py:143: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/reuters.py:144: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQwK6RleOFsZ"
      },
      "source": [
        "Como en el caso anterior, limitamos a 500 palabras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSADYMX5OIW2"
      },
      "source": [
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L802Pzh-MQ_Q"
      },
      "source": [
        "Para construir el modelo para este dataset, tomaremos el modelo con mayor accuracy aplicado en el apartado anterior, el 3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYGo_Zd3MeCE",
        "outputId": "a23785bf-fcab-4c6d-9c36-9567dad3f3b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def create_cnn_model():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(top_words,32,input_length=max_words))\n",
        "  model.add(Convolution1D(filters=32,kernel_size=3,padding='same',activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(250,activation='relu'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "modelReuters = create_cnn_model()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 500, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 250, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 8000)              0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 250)               2000250   \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 2,163,605\n",
            "Trainable params: 2,163,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fyxa9EBMiR7"
      },
      "source": [
        "Lo entrenamos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5i9cXUhMhtp",
        "outputId": "d60013c1-614c-4dbf-b93b-9941d6476752",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "modelReuters.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=10,batch_size=128,verbose=1)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "57/57 [==============================] - 1s 14ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 2/10\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 3/10\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 4/10\n",
            "57/57 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 5/10\n",
            "57/57 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 6/10\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 7/10\n",
            "57/57 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 8/10\n",
            "57/57 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 9/10\n",
            "57/57 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 10/10\n",
            "57/57 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f17965c6a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq7F6QaiMq5y"
      },
      "source": [
        "Finalmente, lo evaluamos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2muquJLeMsQ3",
        "outputId": "b0afe9ce-4ef5-425c-e293-06ee2a18d713",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "scores = modelReuters.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 4.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YqqNefkPTu3"
      },
      "source": [
        "No hemos conseguido un resultado demasiado bueno. Probemos un modelo más."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc4xfGswSqRO",
        "outputId": "47c9232a-48b1-4b5f-c33a-76b830bc0add",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def create_lstm_model():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(top_words,32,input_length=max_words))\n",
        "  model.add(LSTM(100))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "modelRouters2 = create_lstm_model()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPEagHuKSqIM",
        "outputId": "ae85e3cd-253e-41d9-d3f5-4355cfcc7535",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "modelRouters2.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=10,batch_size=128,verbose=1)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 2/10\n",
            "57/57 [==============================] - 2s 36ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 3/10\n",
            "57/57 [==============================] - 2s 36ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 4/10\n",
            "57/57 [==============================] - 2s 36ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 5/10\n",
            "57/57 [==============================] - 2s 36ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 6/10\n",
            "57/57 [==============================] - 2s 35ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 7/10\n",
            "57/57 [==============================] - 2s 36ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 8/10\n",
            "57/57 [==============================] - 2s 36ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 9/10\n",
            "57/57 [==============================] - 2s 36ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n",
            "Epoch 10/10\n",
            "57/57 [==============================] - 2s 36ms/step - loss: 0.0000e+00 - accuracy: 0.0469 - val_loss: 0.0000e+00 - val_accuracy: 0.0529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1797ef03d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkYdpEB2S038",
        "outputId": "f098cf3d-87e2-4318-f903-95d6288aad8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "scores = modelRouters2.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 4.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn4yO6BzTMU0"
      },
      "source": [
        "Desgraciadamente, parece que tampoco mejora."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbqRWAE7Nlli"
      },
      "source": [
        "## Ejercicio opcional \n",
        "\n",
        "A lo largo de la práctica los embeddings se han aprendido al entrenar la propia red. El ejercicio opcional consiste en utilizar embeddings preentrenados y utilizarlos para construir distintos modelos (ten en cuenta que deberás cambiar la estructura de las redes). Para esto puedes seguir el siguiente [tutorial de Keras](https://keras.io/examples/nlp/pretrained_word_embeddings/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvrZj009NlH3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hd_0BCHSlSy"
      },
      "source": [
        "Recuerda guardar tus cambios en tu repositorio de GitHub usando la opción \"Save in GitHub\" del menú File."
      ]
    }
  ]
}